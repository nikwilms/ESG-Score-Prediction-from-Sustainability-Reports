{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../../data/SP500_EGS_Score_avarage_per_year.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    sep=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lower case\n",
    "\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# - to _\n",
    "\n",
    "df.columns = df.columns.str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.company_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.text_preprocessing.preprocess_text import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load or create your DataFrame (replace 'your_data.csv' with the path to your data file)\n",
    "df = pd.read_csv(\n",
    "    \"../data/extracted_text_sustainability_reports.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    sep=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text and get the preprocessed DataFrame\n",
    "preprocessed_df = preprocess_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from gensim import corpora\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ready_to_model/df_filtered_feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \"e_score\",\n",
    "    \"s_score\",\n",
    "    \"g_score\",\n",
    "    \"unnamed: 0\",\n",
    "    \"filename\",\n",
    "    \"ticker\",\n",
    "    \"year\",\n",
    "    \"preprocessed_content\",\n",
    "    \"ner_entities\",\n",
    "    \"company_symbol\"'''\n",
    "\n",
    "\n",
    "# columns to drop\n",
    "columns_to_drop = [\n",
    "\n",
    "    \"total_score\",\n",
    "    \"Unnamed: 0\",\n",
    "]\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"total_score\"]\n",
    "X = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the last two rows\n",
    "X = X.iloc[:-2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.iloc[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.XGBoost.tune_xgb_hyperparameters import tune_xgb_hyperparameters\n",
    "from models.ElasticNet.tune_elasticnet_hyperparameters import tune_elasticnet_hyperparameters\n",
    "from models.GradientBoostingReg.tune_gradientboosting_hyperparameters import tune_gradientboosting_hyperparameters\n",
    "from models.LightGBM.tune_lightgbm_hyperparameters import tune_lightgbm_hyperparameters\n",
    "from models.Lasso.tune_lasso_hyperparameters import tune_lasso_hyperparameters\n",
    "from models.Ridge.tune_ridge_hyperparameters import tune_kernelridge_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_elasticnet_hyperparameters(X_train, y_train, X_test, y_test, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_xgb_hyperparameters(X_train, y_train, X_test, y_test, n_trials=25, n_jobs=5)\n",
    "# [I 2023-10-09 11:51:29,849] Trial 11 finished with value: 4.829379390412605 and parameters: {'learning_rate': 0.005751799616059423, 'max_depth': 15, 'subsample': 0.7721631821405752, 'colsample_bytree': 0.9734742381013841, 'min_child_weight': 5}. Best is trial 11 with value: 4.829379390412605.\n",
    "# Training RMSE: 5.181233593282065, Test RMSE: 4.829379390412605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 11:52:04,187] A new study created in memory with name: no-name-9cea163d-4a60-4583-9c88-1f217ed0d1ad\n",
      "[I 2023-10-10 11:52:09,087] Trial 0 finished with value: 5.8148442143220285 and parameters: {'n_estimators': 253, 'learning_rate': 0.021160872577124762, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: 5.8148442143220285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 6.144727182526734, Test RMSE: 5.8148442143220285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-10-10 11:56:24,123] Trial 1 failed with parameters: {'n_estimators': 326, 'learning_rate': 0.18083913144410743, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/playhub/../models/GradientBoostingReg/tune_gradientboosting_hyperparameters.py\", line 32, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 532, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 610, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 245, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
      "    super()._fit(\n",
      "  File \"/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-10 11:56:24,134] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/playhub/playground_nikita.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/playhub/playground_nikita.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tune_gradientboosting_hyperparameters(X_train, y_train, X_test, y_test, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/playhub/../models/GradientBoostingReg/tune_gradientboosting_hyperparameters.py:41\u001b[0m, in \u001b[0;36mtune_gradientboosting_hyperparameters\u001b[0;34m(X_train, y_train, X_test, y_test, n_trials)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m test_rmse  \u001b[39m# Objective is to minimize test RMSE\u001b[39;00m\n\u001b[1;32m     40\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mn_trials)\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Test RMSE:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/playhub/../models/GradientBoostingReg/tune_gradientboosting_hyperparameters.py:32\u001b[0m, in \u001b[0;36mtune_gradientboosting_hyperparameters.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m neg_mse \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m     28\u001b[0m     model, X_train, y_train, cv\u001b[39m=\u001b[39mkf, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m train_rmse \u001b[39m=\u001b[39m sqrt(\u001b[39m-\u001b[39mneg_mse\u001b[39m.\u001b[39mmean())\n\u001b[0;32m---> 32\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     33\u001b[0m test_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     34\u001b[0m test_rmse \u001b[39m=\u001b[39m sqrt(mean_squared_error(y_test, test_predictions))\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    531\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    533\u001b[0m     X_train,\n\u001b[1;32m    534\u001b[0m     y_train,\n\u001b[1;32m    535\u001b[0m     raw_predictions,\n\u001b[1;32m    536\u001b[0m     sample_weight_train,\n\u001b[1;32m    537\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    538\u001b[0m     X_val,\n\u001b[1;32m    539\u001b[0m     y_val,\n\u001b[1;32m    540\u001b[0m     sample_weight_val,\n\u001b[1;32m    541\u001b[0m     begin_at_stage,\n\u001b[1;32m    542\u001b[0m     monitor,\n\u001b[1;32m    543\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    603\u001b[0m         initial_loss \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    604\u001b[0m             y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    605\u001b[0m             raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    606\u001b[0m             sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    607\u001b[0m         )\n\u001b[1;32m    609\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    611\u001b[0m     i,\n\u001b[1;32m    612\u001b[0m     X,\n\u001b[1;32m    613\u001b[0m     y,\n\u001b[1;32m    614\u001b[0m     raw_predictions,\n\u001b[1;32m    615\u001b[0m     sample_weight,\n\u001b[1;32m    616\u001b[0m     sample_mask,\n\u001b[1;32m    617\u001b[0m     random_state,\n\u001b[1;32m    618\u001b[0m     X_csc,\n\u001b[1;32m    619\u001b[0m     X_csr,\n\u001b[1;32m    620\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[39m# track loss\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    244\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 245\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    247\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    249\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    250\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    258\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tune_gradientboosting_hyperparameters(X_train, y_train, X_test, y_test, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lightgbm_hyperparameters(X_train, y_train, X_test, y_test, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lasso_hyperparameters(X_train, y_train, X_test, y_test, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_kernelridge_hyperparameters(X_train, y_train, X_test, y_test, n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.XGBoost.train_and_evaluate_model import train_and_evaluate_model\n",
    "from models.XGBoost.tune_xgb_hyperparameters import tune_xgb_hyperparameters\n",
    "from models.Random_Forest.tune_rf_hyperparameters import tune_rf_hyperparameters\n",
    "from models.Lasso.tune_lasso_hyperparameters import tune_lasso_hyperparameters\n",
    "from models.Neural_Network.tune_nn_hyperparameters import tune_nn_hyperparameters\n",
    "from models.Ridge.tune_ridge_hyperparameters import tune_ridge_hyperparameters\n",
    "from models.perform_stacking import perform_stacking\n",
    "from models.optimize_stacking import optimize_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(pd.to_numeric, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = tune_rf_hyperparameters(X_train, y_train, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters: {'n_estimators': 266, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None}\n",
    "# Best RMSE: 5.883527888313719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lasso = tune_lasso_hyperparameters(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [I 2023-10-04 17:44:22,225] Trial 23 finished with value: 4.497792051287519 and parameters: {'alpha': 0.08706251396825564}. Best is trial 23 with value: 4.497792051287519.\n",
    "# Training RMSE: 5.277817560823488, Test RMSE: 4.497792051287519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ridge = tune_ridge_hyperparameters(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'alpha': 0.9992235606570956}\n",
    "# Best Test RMSE: 5.210845073517565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_nn = tune_nn_hyperparameters(X_train, y_train, X_test, y_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'hidden_layer_sizes': (50, 50), 'activation': 'tanh', 'alpha': 0.00010434024177879637}\n",
    "# Best Test RMSE: 6.9895163966718235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = tune_xgb_hyperparameters(X_train, y_train, n_trials=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'learning_rate': 0.02998822459568964, 'max_depth': 5, 'subsample': 0.7095254982521659, 'colsample_bytree': 0.6113315193397809, 'min_child_weight': 13}\n",
    "# Best RMSE: 5.098858708449277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/XGBoost/best_params_features_cleaned.pkl', 'rb') as f:\n",
    "    best_params_xgb = pickle.load(f)\n",
    "\n",
    "with open('../models/Lasso/best_params_lasso.pkl', 'rb') as f:\n",
    "    best_params_lasso = pickle.load(f)\n",
    "\n",
    "with open('../models/Ridge/best_params_ridge.pkl', 'rb') as f:\n",
    "    best_params_ridge = pickle.load(f)\n",
    "    \n",
    "with open('../models/Random_Forest/best_params_rf.pkl', 'rb') as f:\n",
    "    best_params_rf = pickle.load(f)\n",
    "\n",
    "with open('../models/Neural_Network/best_params_nn.pkl', 'rb') as f:\n",
    "    best_params_nn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimize_stacking(X, y, n_trials=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model, test_rmse = perform_stacking(X, y, best_params_lasso, best_params_rf, best_params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STACKING MODEL\n",
    "# base models: ['lasso', 'lasso_lars_cv', 'xgb', 'rf', 'ridge_cv']\n",
    "# meta model: gradient_boosting_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTING REGRESSOR\n",
    "# Root Mean Squared Error (RMSE) for test set: 5.170260299240855\n",
    "# Root Mean Squared Error (RMSE) for training set: 3.3442587249065046\n",
    "\n",
    "# ADABOOST REGRESSOR\n",
    "# Root Mean Squared Error (RMSE) for test set: 4.644395241213758\n",
    "# Root Mean Squared Error (RMSE) for training set: 2.0869823753568713\n",
    "\n",
    "# GRADIENT BOOSTING REGRESSOR\n",
    "# Root Mean Squared Error (RMSE) for test set: 4.496692472551547\n",
    "# Root Mean Squared Error (RMSE) for training set: 1.653435201586618\n",
    "\n",
    "# ADA BOOST REGRESSOR\n",
    "# Root Mean Squared Error (RMSE) for test set: 5.401425699939552\n",
    "# Root Mean Squared Error (RMSE) for training set: 4.3236806588367855\n",
    "\n",
    "# LGBM REGRESSOR\n",
    "# Root Mean Squared Error (RMSE) for test set: 4.546673980636338\n",
    "# Root Mean Squared Error (RMSE) for training set: 0.2985705242417246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle file from the best_params_xgb\n",
    "with open('../models/XGBoost/best_params_features_cleaned.pkl', 'rb') as f:\n",
    "    best_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_model, rmse_val, feature_importance_df = train_and_evaluate_model(X_train, y_train, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_feature_importance_df = feature_importance_df[feature_importance_df['Importance'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df = df.loc[:, filtered_feature_importance_df['Feature'].tolist() + ['total_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df.to_csv(\"../data/ready_to_model/filtered_feature_importance_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = fetch_and_merge_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percent = df_cleaned.isnull().mean() * 100\n",
    "\n",
    "# Sort the columns by percentage of missing values in descending order\n",
    "missing_percent_sorted = missing_percent.sort_values(ascending=False)\n",
    "\n",
    "# Show the sorted series\n",
    "print(missing_percent_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = final_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_with_nans(df, threshold=800):\n",
    "    nan_count = final_df.isna().sum()\n",
    "    columns_to_remove = nan_count[nan_count > threshold].index.tolist()\n",
    "    df_cleaned = final_df.drop(columns=columns_to_remove)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = remove_columns_with_nans(df, threshold=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"../data/ready_to_model/df_cleaned_with_yfinance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting columns by the number of NaN values (in descending order)\n",
    "sorted_nan_count = nan_count.sort_values(ascending=False)\n",
    "\n",
    "print(sorted_nan_count.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_csv(\"../data/ready_to_model/df_cleaned_with_yfinance.csv\", index_col=0, parse_dates=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
