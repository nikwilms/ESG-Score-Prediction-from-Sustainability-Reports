{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../../data/SP500_EGS_Score_avarage_per_year.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    sep=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lower case\n",
    "\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# - to _\n",
    "\n",
    "df.columns = df.columns.str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.company_symbol.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.text_preprocessing.preprocess_text import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load or create your DataFrame (replace 'your_data.csv' with the path to your data file)\n",
    "df = pd.read_csv(\n",
    "    \"../data/extracted_text_sustainability_reports.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    sep=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text and get the preprocessed DataFrame\n",
    "preprocessed_df = preprocess_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from gensim import corpora\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LDA_optuna_tuning.tune_lda_optuna import train_lda, compute_coherence\n",
    "from models.LDA_optuna_tuning.call_optuna_tune import (\n",
    "    preprocess_data,\n",
    "    execute_optuna_study,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import tpot2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ready_to_model/df_filtered_feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\"e_score\",\n",
    "\"s_score\",\n",
    "\"g_score\",\n",
    "\"unnamed: 0\",\n",
    "\"filename\",\n",
    "\"ticker\",\n",
    "\"year\",\n",
    "\"preprocessed_content\",\n",
    "\"ner_entities\",\n",
    "\"company_symbol\",'''\n",
    "\n",
    "# columns to drop\n",
    "columns_to_drop = [\n",
    "\n",
    "    \"total_score\",\n",
    "    \"Unnamed: 0\"\n",
    "]\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"total_score\"]\n",
    "X = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the last two rows\n",
    "X = X.iloc[:-2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.iloc[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sklearn.metrics.get_scorer(\"neg_mean_squared_error\")\n",
    "\n",
    "# Initialize TPOT2 regressor with K-Fold cross-validation\n",
    "est = tpot2.TPOTEstimatorSteadyState(\n",
    "    n_jobs=6,\n",
    "    cv=KFold(n_splits=5),  # 5-Fold cross-validation\n",
    "    verbose=2,\n",
    "    classification=False,\n",
    "    scorers=[scorer],\n",
    "    scorers_weights=[1],\n",
    "    max_eval_time_seconds=60 * 10,\n",
    "    max_time_seconds=60 * 90,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "est.fit(X_train, y_train)\n",
    "print('Done fitting/training TPOT2 session.')\n",
    "\n",
    "\n",
    "df_individuals = est.evaluated_individuals\n",
    "\n",
    "# Convert the 'mean_squared_error' column to numeric, errors='coerce' will replace non-numeric with NaN\n",
    "df_individuals['mean_squared_error'] = pd.to_numeric(df_individuals['mean_squared_error'], errors='coerce')\n",
    "\n",
    "# Drop NaN values\n",
    "filtered_df = df_individuals.dropna(subset=['mean_squared_error'])\n",
    "\n",
    "# Sort the DataFrame by 'mean_squared_error' and get the top 10\n",
    "top_10_mse = filtered_df.nlargest(10, 'mean_squared_error')\n",
    "\n",
    "print(est.pareto_front)\n",
    "print(top_10_mse)\n",
    "print(est.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_mse = filtered_df.nlargest(30, 'mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the top 30 models to csv\n",
    "top_30_mse.to_csv(\"../data/model_data/top_30_mse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.XGBoost.train_and_evaluate_model import train_and_evaluate_model\n",
    "from models.XGBoost.tune_xgb_hyperparameters import tune_xgb_hyperparameters\n",
    "from models.Random_Forest.tune_rf_hyperparameters import tune_rf_hyperparameters\n",
    "from models.Lasso.tune_lasso_hyperparameters import tune_lasso_hyperparameters\n",
    "from models.Neural_Network.tune_nn_hyperparameters import tune_nn_hyperparameters\n",
    "from models.Ridge.tune_ridge_hyperparameters import tune_ridge_hyperparameters\n",
    "from models.perform_stacking import perform_stacking\n",
    "from models.optimize_stacking import optimize_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(pd.to_numeric, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = tune_rf_hyperparameters(X_train, y_train, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters: {'n_estimators': 266, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None}\n",
    "# Best RMSE: 5.883527888313719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lasso = tune_lasso_hyperparameters(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [I 2023-10-04 17:44:22,225] Trial 23 finished with value: 4.497792051287519 and parameters: {'alpha': 0.08706251396825564}. Best is trial 23 with value: 4.497792051287519.\n",
    "# Training RMSE: 5.277817560823488, Test RMSE: 4.497792051287519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ridge = tune_ridge_hyperparameters(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'alpha': 0.9992235606570956}\n",
    "# Best Test RMSE: 5.210845073517565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_nn = tune_nn_hyperparameters(X_train, y_train, X_test, y_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'hidden_layer_sizes': (50, 50), 'activation': 'tanh', 'alpha': 0.00010434024177879637}\n",
    "# Best Test RMSE: 6.9895163966718235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = tune_xgb_hyperparameters(X_train, y_train, n_trials=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'learning_rate': 0.02998822459568964, 'max_depth': 5, 'subsample': 0.7095254982521659, 'colsample_bytree': 0.6113315193397809, 'min_child_weight': 13}\n",
    "# Best RMSE: 5.098858708449277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/XGBoost/best_params_features_cleaned.pkl', 'rb') as f:\n",
    "    best_params_xgb = pickle.load(f)\n",
    "\n",
    "with open('../models/Lasso/best_params_lasso.pkl', 'rb') as f:\n",
    "    best_params_lasso = pickle.load(f)\n",
    "\n",
    "with open('../models/Ridge/best_params_ridge.pkl', 'rb') as f:\n",
    "    best_params_ridge = pickle.load(f)\n",
    "    \n",
    "with open('../models/Random_Forest/best_params_rf.pkl', 'rb') as f:\n",
    "    best_params_rf = pickle.load(f)\n",
    "\n",
    "with open('../models/Neural_Network/best_params_nn.pkl', 'rb') as f:\n",
    "    best_params_nn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimize_stacking(X, y, n_trials=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/nikitawilms/Documents/ffm-ds-23-2/ESG-Score-Prediction-from-Sustainability-Reports/.venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stacking_model, test_rmse = perform_stacking(X, y, best_params_lasso, best_params_rf, best_params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, validation_rmse, feature_importances_df = train_and_evaluate_model(X_train, y_train, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_feature_importances_df = feature_importances_df[feature_importances_df['Importance'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df = df.loc[:, filtered_feature_importances_df['Feature'].tolist() + ['total_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_main_df.to_csv(\"../data/ready_to_model/filtered_feature_importance_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def fetch_data_for_row(named_tuple_row):\n",
    "    ticker = \"Unknown\"  # Initialize with a default value\n",
    "    year = \"Unknown\"    # Initialize with a default value\n",
    "    \n",
    "    try:\n",
    "        ticker = named_tuple_row.ticker\n",
    "        year = named_tuple_row.year\n",
    "\n",
    "        yf_ticker = yf.Ticker(ticker)\n",
    "        financials = yf_ticker.financials\n",
    "        cashflow = yf_ticker.cashflow\n",
    "        balance = yf_ticker.balance_sheet\n",
    "        info = {k: v for k, v in yf_ticker.info.items() if isinstance(v, (int, float))}\n",
    "\n",
    "        financials = financials.loc[:, pd.to_datetime(financials.columns).year == year].transpose()\n",
    "        cashflow = cashflow.loc[:, pd.to_datetime(cashflow.columns).year == year].transpose()\n",
    "        balance = balance.loc[:, pd.to_datetime(balance.columns).year == year].transpose()\n",
    "        info_df = pd.DataFrame([info])\n",
    "\n",
    "        financials.columns = 'financials_' + financials.columns.astype(str)\n",
    "        cashflow.columns = 'cashflow_' + cashflow.columns.astype(str)\n",
    "        balance.columns = 'balance_' + balance.columns.astype(str)\n",
    "        info_df.columns = 'info_' + info_df.columns.astype(str)\n",
    "\n",
    "        merged_data = pd.concat([financials, cashflow, balance, info_df], axis=1)\n",
    "        merged_data['ticker'] = ticker\n",
    "        merged_data['year'] = year\n",
    "\n",
    "        return merged_data.reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in fetch_data_for_row for ticker: {ticker} and year: {year}. Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_merge_data(df):\n",
    "    try:\n",
    "        # Initialize an empty list to store fetched data\n",
    "        fetched_data_list = []\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            fetched_data_list = list(executor.map(fetch_data_for_row, df.itertuples(index=False)))\n",
    "\n",
    "        # Concatenate all the fetched data\n",
    "        new_data = pd.concat([data.iloc[[0]] for data in fetched_data_list if not data.empty], ignore_index=True)\n",
    "\n",
    "        # Debug: Print the shape and columns of new_data\n",
    "        print(f\"new_data shape: {new_data.shape}, columns: {new_data.columns}\")\n",
    "\n",
    "        # Merge new_data with df based on 'ticker' and 'year'\n",
    "        final_df = pd.merge(df, new_data, on=['ticker', 'year'], how='left')\n",
    "\n",
    "        return final_df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in fetch_and_merge_data: {e}\")\n",
    "        return df  # Return the original DataFrame as a fallback\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# df = pd.DataFrame({'ticker': ['AAPL', 'GOOGL'], 'year': [2020, 2021]})\n",
    "# final_df = fetch_and_merge_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = fetch_and_merge_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percent = df_cleaned.isnull().mean() * 100\n",
    "\n",
    "# Sort the columns by percentage of missing values in descending order\n",
    "missing_percent_sorted = missing_percent.sort_values(ascending=False)\n",
    "\n",
    "# Show the sorted series\n",
    "print(missing_percent_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = final_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_with_nans(df, threshold=800):\n",
    "    nan_count = final_df.isna().sum()\n",
    "    columns_to_remove = nan_count[nan_count > threshold].index.tolist()\n",
    "    df_cleaned = final_df.drop(columns=columns_to_remove)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = remove_columns_with_nans(df, threshold=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"../data/ready_to_model/df_cleaned_with_yfinance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting columns by the number of NaN values (in descending order)\n",
    "sorted_nan_count = nan_count.sort_values(ascending=False)\n",
    "\n",
    "print(sorted_nan_count.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_csv(\"../data/ready_to_model/df_cleaned_with_yfinance.csv\", index_col=0, parse_dates=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
